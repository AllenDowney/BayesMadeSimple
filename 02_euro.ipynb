{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistics Made Simple\n",
    "\n",
    "Code and exercises from my workshop on Bayesian statistics in Python.\n",
    "\n",
    "Copyright 2020 Allen Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Euro problem\n",
    "\n",
    "Here's a problem from David MacKay's book, [*Information Theory, Inference, and Learning Algorithms*](http://www.inference.org.uk/mackay/itila/p0.html), which is the book where I first learned about Bayesian statistics.  MacKay writes:\n",
    "\n",
    "> A statistical statement appeared in The Guardian on\n",
    "Friday January 4, 2002:\n",
    ">\n",
    "> >\"When spun on edge 250 times, a Belgian one-euro coin came\n",
    "up heads 140 times and tails 110. ‘It looks very suspicious\n",
    "to me’, said Barry Blight, a statistics lecturer at the London\n",
    "School of Economics. ‘If the coin were unbiased the chance of\n",
    "getting a result as extreme as that would be less than 7%’.\"\n",
    ">\n",
    "> But [asks MacKay] do these data give evidence that the coin is biased rather than fair?\n",
    "\n",
    "To answer this question, we have to make some modeling choices.\n",
    "\n",
    "First, let's assume that if you spin a coin on edge, there is some probability that it will land heads up.  I'll call that probability $x$.\n",
    "\n",
    "Second, let's assume that $x$ varies from one coin to the next, depending on how the coin is balanced and maybe some other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these assumptions we can formulate MacKay's question as an inference problem: given the data --- 140 heads and 110 tails --- what do we think $x$ is for this coin?\n",
    "\n",
    "This formulation is similar to the 101 Bowls problem we saw in the previous notebook.\n",
    "\n",
    "But in the 101 Bowls problem, we are told that we choose a bowl at random, which implies that all bowls have the same prior probability.\n",
    "\n",
    "For the Euro problem, we have to think harder about the prior.  What values of $x$ do you think are reasonable?\n",
    "\n",
    "It seems likely that many coins are \"fair\", meaning that the probability of heads is close to 50%.  Do you think there are coins where $x$ is 75%?  How about 90%?\n",
    "\n",
    "To be honest, I don't really know.  To get started, I will assume that all values of $x$, from 0% to 100%, are equally likely.  Then we'll come back and try another prior.\n",
    "\n",
    "Here's a uniform prior from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 1, num=101)\n",
    "p = 1/101\n",
    "prior = pd.Series(p, index=xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.plot()\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Prior');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the likelihoods for heads and tails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_heads = xs\n",
    "likelihood_tails = 1 - xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we toss the coin twice and get one heads and one tails.\n",
    "\n",
    "We can compute the posterior probability for each value of $x$ like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = prior * likelihood_heads * likelihood_tails\n",
    "posterior /= posterior.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what the posterior distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.plot()\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Posterior')\n",
    "\n",
    "posterior.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Go back and run the update again for the following outcomes:\n",
    "\n",
    "* Two heads, one tails.\n",
    "\n",
    "* 7 heads, 3 tails.\n",
    "\n",
    "* 70 heads, 30 tails.\n",
    "\n",
    "* 140 heads, 110 tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better prior\n",
    "\n",
    "Remember that this result is based on a uniform prior, which assumes that any value of $x$ from 0 to 100 is equally likely.\n",
    "\n",
    "Given what we know about coins, that's probably not true.  I can believe that if you spin a lop-sided coin on edge, it might be somewhat more likely to land on heads or tails.  \n",
    "\n",
    "But unless the coin is heavily weighted on one side, I would be surprised if $x$ were greater than 60% or less than 40%.\n",
    "\n",
    "Of course, I could be wrong, but in general I would expect to find $x$ closer to 50%, and I would be surprised to find it near 0% or 100%.\n",
    "\n",
    "We can represent that prior belief with a triangle-shaped prior.\n",
    "Here's an array that ramps up from 0 to 49 and ramps down from 50 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_up = np.arange(50)\n",
    "ramp_down = np.arange(50, -1, -1)\n",
    "\n",
    "ps = np.append(ramp_up, ramp_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll put it in a `Series` and normalize it so it adds up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle = pd.Series(ps, xs)\n",
    "triangle /= triangle.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the triangle prior looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle.plot(color='C1')\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Triangle prior');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update it with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior1 = prior * likelihood_heads**140 * likelihood_tails**110\n",
    "posterior1 /= posterior1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior2 = triangle * likelihood_heads**140 * likelihood_tails**110\n",
    "posterior2 /= posterior2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the results, along with the posterior based on a uniform prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior1.plot(label='Uniform prior')\n",
    "posterior2.plot(label='Triangle prior')\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Posterior after 140 heads, 110 tails')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distributions are almost identical because, in this case, we have enough data to \"swamp the prior\"; that is, the posteriors depend strongly on the data and only weakly on the priors.\n",
    "\n",
    "This is good news, because it suggests that we can use data to resolve arguments.  Suppose two people disagree about the correct prior.  If neither can persuade the other, they might have to agree to disagree.\n",
    "\n",
    "But if they get new data, and each of them does a Bayesian update, they will usually find their beliefs converging.\n",
    "\n",
    "And with enough data, the remaining difference can be so small that it makes no difference in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the posterior distribution\n",
    "\n",
    "The posterior distribution contains all of the information we have about the value of $x$.  But sometimes we want to summarize this information.\n",
    "\n",
    "We have already seen one way to summarize a posterior distribution, the Maximum Aposteori Probability, or MAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior1.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`idxmax` returns the value of $x$ with the highest probability.\n",
    "\n",
    "In this example, we get the same MAP with the triangle prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior2.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to summarize the posterior distribution is the posterior mean.\n",
    "\n",
    "Given a set of values, $x_i$, and the corresponding probabilities, $p_i$, the mean of the distribution is:\n",
    "\n",
    "$\\sum_i x_i p_i$\n",
    "\n",
    "The following function takes a Pmf and computes its mean.  Note that this function only works correctly if the Pmf is normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmf_mean(pmf):\n",
    "    \"\"\"Compute the mean of a PMF.\n",
    "    \n",
    "    pmf: Series representing a PMF\n",
    "    \n",
    "    return: float\n",
    "    \"\"\"\n",
    "    return np.sum(pmf.index * pmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the posterior mean based on the uniform prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_mean(posterior1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the posterior mean with the triangle prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_mean(posterior2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior means are not identical, but they are close enough that the difference probably doesn't matter.\n",
    "\n",
    "In this example, the posterior mean is very close to the MAP.  That's true when the posterior distribution is symmetric, but it is not always true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If someone asks what we think $x$ is, the MAP or the posterior mean might be a good answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credible intervals\n",
    "\n",
    "Another way to summarize a posterior distribution is a credible interval, which is a range of quantities whose probabilities add up to a given total.\n",
    "\n",
    "The following function takes a `Series` as a parameter and a probability, `prob`, and return an interval that contains the given probability.\n",
    "\n",
    "If you are interested, it computes the cumulative distribution function (CDF) and then uses interpolation to estimate percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def credible_interval(pmf, prob):\n",
    "    \"\"\"Compute the mean of a PMF.\n",
    "    \n",
    "    pmf: Series representing a PMF\n",
    "    prob: probability of the interval\n",
    "    \n",
    "    return: pair of float\n",
    "    \"\"\"\n",
    "    # make the CDF\n",
    "    xs = pmf.index\n",
    "    ys = pmf.cumsum()\n",
    "    \n",
    "    # compute the probabilities\n",
    "    p = (1-prob)/2\n",
    "    ps = [p, 1-p]\n",
    "    \n",
    "    # interpolate the inverse CDF\n",
    "    options = dict(bounds_error=False,\n",
    "                   fill_value=(xs[0], xs[-1]), \n",
    "                   assume_sorted=True)\n",
    "    interp = interp1d(ys, xs, **options)\n",
    "    return interp(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the 90% credible interval for `posterior1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_interval(posterior1, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for `posterior2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_interval(posterior2, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The credible interval for `posterior2` is slightly narrower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
